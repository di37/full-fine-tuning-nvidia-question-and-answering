{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to the main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isham/Desktop/machine-learning-projects/fine-tuning-q-and-a\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "from utils import FINAL_MODEL_PATH, DEVICE, BASE_MODEL_PATH, MODEL_ID, PROCESSED_DATA_DIR, SENTENCE_EMBEDDING_MODEL\n",
    "from utils import full_prompt, clear_gpu_memory, generate_response, cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the following question:\n",
      "\n",
      "What is cuda insight?\n",
      "Answer:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_prompt(\"What is cuda insight?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = AutoModelForSeq2SeqLM.from_pretrained(FINAL_MODEL_PATH).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINAL_MODEL_PATH)\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda insight is a technology that provides insights into the behavior of cuda threads and their interactions enabling developers to optimize and optimize their cuda applications'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model=trained_model, tokenizer=tokenizer, prompt=\"What is cuda insight?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare with the original base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_PATH).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(iv)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model=original_model, tokenizer=tokenizer, prompt=\"What is cuda insight?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pick few examples from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{PROCESSED_DATA_DIR}/test.csv\")\n",
    "test_sample = test_df.sample(n=5, random_state=42)\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(iv)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model=original_model, tokenizer=tokenizer, prompt=\"What is cuda insight?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['generated_answer_original'] = test_sample['question'].apply(lambda x: generate_response(model=original_model, tokenizer=tokenizer, prompt=full_prompt(x)))\n",
    "test_sample['generated_answer_trained'] = test_sample['question'].apply(lambda x: generate_response(model=trained_model, tokenizer=tokenizer, prompt=full_prompt(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>generated_answer_original</th>\n",
       "      <th>generated_answer_trained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>what principles guide the development and supp...</td>\n",
       "      <td>nvidia ai enterprise is guided by principles o...</td>\n",
       "      <td>(iv)</td>\n",
       "      <td>the nvidia ai enterprise aims to support the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>how does unified memory simplify memory manage...</td>\n",
       "      <td>unified memory furnishes a unified memory spac...</td>\n",
       "      <td>(iv)</td>\n",
       "      <td>unified memory furnishes a unified virtual add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>how is the theoretical peak bandwidth of a gpu...</td>\n",
       "      <td>the theoretical peak bandwidth is calculated b...</td>\n",
       "      <td>(iv)</td>\n",
       "      <td>the theoretical peak bandwidth of a gpu is cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>how can you define dependencies for a kit file</td>\n",
       "      <td>dependencies for a kit file are defined in the...</td>\n",
       "      <td>(iv)</td>\n",
       "      <td>dependencies for a kit file are defined in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>how does hardwareaccelerated gpu scheduling af...</td>\n",
       "      <td>hardwareaccelerated gpu scheduling a model int...</td>\n",
       "      <td>(iv)</td>\n",
       "      <td>hardwareaccelerated gpu scheduling significant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "732  what principles guide the development and supp...   \n",
       "657  how does unified memory simplify memory manage...   \n",
       "168  how is the theoretical peak bandwidth of a gpu...   \n",
       "86      how can you define dependencies for a kit file   \n",
       "411  how does hardwareaccelerated gpu scheduling af...   \n",
       "\n",
       "                                                answer  \\\n",
       "732  nvidia ai enterprise is guided by principles o...   \n",
       "657  unified memory furnishes a unified memory spac...   \n",
       "168  the theoretical peak bandwidth is calculated b...   \n",
       "86   dependencies for a kit file are defined in the...   \n",
       "411  hardwareaccelerated gpu scheduling a model int...   \n",
       "\n",
       "    generated_answer_original  \\\n",
       "732                      (iv)   \n",
       "657                      (iv)   \n",
       "168                      (iv)   \n",
       "86                       (iv)   \n",
       "411                      (iv)   \n",
       "\n",
       "                              generated_answer_trained  \n",
       "732  the nvidia ai enterprise aims to support the d...  \n",
       "657  unified memory furnishes a unified virtual add...  \n",
       "168  the theoretical peak bandwidth of a gpu is cal...  \n",
       "86   dependencies for a kit file are defined in the...  \n",
       "411  hardwareaccelerated gpu scheduling significant...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trained_model\n",
    "del original_model\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare similarity scores between answer and trained answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.drop(columns=['generated_answer_original'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentence transformer model\n",
    "sentence_model = SentenceTransformer(SENTENCE_EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_original = sentence_model.encode(test_sample['answer'].tolist())\n",
    "embeddings_generated = sentence_model.encode(test_sample['generated_answer_trained'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarities and add them to the dataframe\n",
    "test_sample['cosine_similarity'] = [cosine_similarity(embeddings_original[i], embeddings_generated[i]) for i in range(len(test_sample))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>generated_answer_trained</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what principles guide the development and supp...</td>\n",
       "      <td>nvidia ai enterprise is guided by principles o...</td>\n",
       "      <td>the nvidia ai enterprise aims to support the d...</td>\n",
       "      <td>0.707371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how does unified memory simplify memory manage...</td>\n",
       "      <td>unified memory furnishes a unified memory spac...</td>\n",
       "      <td>unified memory furnishes a unified virtual add...</td>\n",
       "      <td>0.801617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how is the theoretical peak bandwidth of a gpu...</td>\n",
       "      <td>the theoretical peak bandwidth is calculated b...</td>\n",
       "      <td>the theoretical peak bandwidth of a gpu is cal...</td>\n",
       "      <td>0.688995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how can you define dependencies for a kit file</td>\n",
       "      <td>dependencies for a kit file are defined in the...</td>\n",
       "      <td>dependencies for a kit file are defined in the...</td>\n",
       "      <td>0.754526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how does hardwareaccelerated gpu scheduling af...</td>\n",
       "      <td>hardwareaccelerated gpu scheduling a model int...</td>\n",
       "      <td>hardwareaccelerated gpu scheduling significant...</td>\n",
       "      <td>0.806502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  what principles guide the development and supp...   \n",
       "1  how does unified memory simplify memory manage...   \n",
       "2  how is the theoretical peak bandwidth of a gpu...   \n",
       "3     how can you define dependencies for a kit file   \n",
       "4  how does hardwareaccelerated gpu scheduling af...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  nvidia ai enterprise is guided by principles o...   \n",
       "1  unified memory furnishes a unified memory spac...   \n",
       "2  the theoretical peak bandwidth is calculated b...   \n",
       "3  dependencies for a kit file are defined in the...   \n",
       "4  hardwareaccelerated gpu scheduling a model int...   \n",
       "\n",
       "                            generated_answer_trained  cosine_similarity  \n",
       "0  the nvidia ai enterprise aims to support the d...           0.707371  \n",
       "1  unified memory furnishes a unified virtual add...           0.801617  \n",
       "2  the theoretical peak bandwidth of a gpu is cal...           0.688995  \n",
       "3  dependencies for a kit file are defined in the...           0.754526  \n",
       "4  hardwareaccelerated gpu scheduling significant...           0.806502  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: what principles guide the development and support of nvidia ai enterprise\n",
      "Actual Answer: nvidia ai enterprise is guided by principles of security stability api stability and enterprisegrade support\n",
      "Predicted Answer: the nvidia ai enterprise aims to support the development and support of nvidia ai enterprise with a focus on enhancing enterprise support and fostering ai enterprise\n",
      "Cosine Similarity: 0.7073711156845093\n",
      "\n",
      "Question 2: how does unified memory simplify memory management in cuda\n",
      "Actual Answer: unified memory furnishes a unified memory space accessible by gpus and cpus simplifying memory allocation and access across both processing units\n",
      "Predicted Answer: unified memory furnishes a unified virtual address space allowing virtual memory allocations and allocations in cuda can be managed using unified memory this eliminates the need for explicit memory allocations in cuda cpu code\n",
      "Cosine Similarity: 0.8016171455383301\n",
      "\n",
      "Question 3: how is the theoretical peak bandwidth of a gpu calculated in the code sample\n",
      "Actual Answer: the theoretical peak bandwidth is calculated by querying the devices memory clock rate and memory bus width using the function cudagetdeviceproperties\n",
      "Predicted Answer: the theoretical peak bandwidth of a gpu is calculated by comparing the theoretical bandwidth of a gpu to the theoretical bandwidth of a gpu\n",
      "Cosine Similarity: 0.6889948844909668\n",
      "\n",
      "Question 4: how can you define dependencies for a kit file\n",
      "Actual Answer: dependencies for a kit file are defined in the dependencies section using the format extensionname for example dependencies omnikitwindowscripteditor defines a dependency on the omnikitwindowscripteditor extension\n",
      "Predicted Answer: dependencies for a kit file are defined in the dependencies section of the kit file\n",
      "Cosine Similarity: 0.7545263767242432\n",
      "\n",
      "Question 5: how does hardwareaccelerated gpu scheduling affect performance on wsl2\n",
      "Actual Answer: hardwareaccelerated gpu scheduling a model introduced by microsoft significantly improves performance on wsl2 by directly exposing hardware queues to cuda this model eliminates the need to batch kernel launches into submissions reducing latency and improving throughput\n",
      "Predicted Answer: hardwareaccelerated gpu scheduling significantly enhances performance on wsl2 affecting gpu scheduling overhead on wsl2 gpu scheduling impacts performance on wsl2 by affecting gpu scheduling and gpu scheduling on wsl2 gpu scheduling impacts performance on wsl2 affecting performance on wsl2\n",
      "Cosine Similarity: 0.8065019249916077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Question {i+1}: {test_sample['question'][i]}\")\n",
    "    print(f\"Actual Answer: {test_sample['answer'][i]}\")\n",
    "    print(f\"Predicted Answer: {test_sample['generated_answer_trained'][i]}\")\n",
    "    print(f\"Cosine Similarity: {test_sample['cosine_similarity'][i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- **Conclusion for Question 1:** The predicted answer captures the essence but misses specific details like \"security\" and \"API stability.\" The emphasis on fostering and enhancing support aligns with the actual answer.\n",
    "- **Conclusion for Question 2:** Both answers refer to the simplification of memory management with CUDA's unified memory, though the predicted answer adds the aspect of a virtual address space, which is accurate and provides a bit more technical insight.\n",
    "- **Conclusion for Question 3:** The predicted answer is circular and doesn't provide a meaningful method for calculating bandwidth. The actual answer gives a clear method for calculation using specific properties.\n",
    "- **Conclusion for Question 4:** Both answers provide a correct definition of where dependencies are defined in a kit file, with the predicted answer providing an example of a specific dependency.\n",
    "- **Conclusion for Question 5:** The predicted answer is somewhat redundant and less specific than the actual answer. It states the effect on performance but lacks the how â€“ the details about reducing latency and improving throughput.\n",
    "\n",
    "Overall, the predicted answers show some alignment with the actual answers but tend to be less specific or miss certain details. The model seems to understand the general context but lacks precision in technical specifics, and in one case, the predicted answer was not useful. The cosine similarity scores reflect the varying degrees of alignment between the predicted and actual answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestions for Improvement\n",
    "\n",
    "- **Enhance Training Data:** Include more detailed and technical content in the training dataset to improve specificity.\n",
    "- **Permutation and Combination of Hyper Parameters:** Fine-tune the model's parameters to focus on technical accuracy and detail retention.\n",
    "- **Use Domain-Specific Models:** Consider training or using a domain-specific model that specializes in technical and programming language.\n",
    "- **Post-Processing Predictions:** Implement a post-processing step to check for and correct circular or redundant predictions.\n",
    "- **Evaluation Metrics:** Utilize more robust evaluation metrics that can capture the effectiveness of technical content beyond cosine similarity, like BLEU score for language translation accuracy.\n",
    "- **User Feedback Loop:** Incorporate user feedback to continuously improve model predictions over time.\n",
    "- Use base model with more parameter e.g. flan-t5-large"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tuning-q-and-a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
