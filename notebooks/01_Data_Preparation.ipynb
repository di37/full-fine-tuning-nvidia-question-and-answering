{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to the main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isham/Desktop/machine-learning-projects/fine-tuning-q-and-a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isham/anaconda3/envs/fine-tuning-q-and-a/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DATASET_ID_OR_URL, DATA_DIR, DATA_PATH, PROCESSED_DATA_DIR\n",
    "from utils import clean_text\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"data/nvidia-documentation-question-and-answer-pairs\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(DATASET_ID_OR_URL, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>4982</td>\n",
       "      <td>What was the purpose of setting up the DGX RAI...</td>\n",
       "      <td>In version 2 of the pipeline, the DGX RAID mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>4450</td>\n",
       "      <td>When will the full programming model enhanceme...</td>\n",
       "      <td>The full programming model enhancements for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>4513</td>\n",
       "      <td>What impact does the PTX6 memory consistency m...</td>\n",
       "      <td>The PTX6 memory consistency model introduced s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>4836</td>\n",
       "      <td>What technologies and framework did the resear...</td>\n",
       "      <td>The researchers used the MatConvNet framework,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>3800</td>\n",
       "      <td>What does the source-to-instruction correlatio...</td>\n",
       "      <td>The source-to-instruction correlation view in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           question  \\\n",
       "4982        4982  What was the purpose of setting up the DGX RAI...   \n",
       "4450        4450  When will the full programming model enhanceme...   \n",
       "4513        4513  What impact does the PTX6 memory consistency m...   \n",
       "4836        4836  What technologies and framework did the resear...   \n",
       "3800        3800  What does the source-to-instruction correlatio...   \n",
       "\n",
       "                                                 answer  \n",
       "4982  In version 2 of the pipeline, the DGX RAID mem...  \n",
       "4450  The full programming model enhancements for th...  \n",
       "4513  The PTX6 memory consistency model introduced s...  \n",
       "4836  The researchers used the MatConvNet framework,...  \n",
       "3800  The source-to-instruction correlation view in ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset into Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (4974, 2)\n",
      "Validation set shape: (1067, 2)\n",
      "Test set shape: (1067, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Settings for 70 - 15 - 15 split of training, validation, and test datasets\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.15, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1765, random_state=42)\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Validation set shape: {val_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4974 entries, 4221 to 3305\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  4974 non-null   object\n",
      " 1   answer    4974 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1067 entries, 5559 to 1366\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  1067 non-null   object\n",
      " 1   answer    1067 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 25.0+ KB\n"
     ]
    }
   ],
   "source": [
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1067 entries, 4982 to 265\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  1067 non-null   object\n",
      " 1   answer    1067 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 25.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset which indicates its well curated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question'] = train_df['question'].apply(clean_text)\n",
    "val_df['question'] = val_df['question'].apply(clean_text)\n",
    "test_df['question'] = test_df['question'].apply(clean_text)\n",
    "\n",
    "train_df['answer'] = train_df['answer'].apply(clean_text)\n",
    "val_df['answer'] = val_df['answer'].apply(clean_text)\n",
    "test_df['answer'] = test_df['answer'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"test.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tuning-q-and-a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
